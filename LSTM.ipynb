{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n"
      ],
      "metadata": {
        "id": "70IdqHbjgT1x"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"Cleened_Dataset_Final.csv\")\n",
        "\n",
        "x = data[['Age', 'SystolicBP', 'DiastolicBP', 'BS', 'BodyTemp', 'HeartRate']]\n",
        "y = data['RiskLevel']"
      ],
      "metadata": {
        "id": "R9GZ37Ofh0vQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "num_classes = np.unique(y).shape[0]\n",
        "max_seq_length = X_train.shape[1]"
      ],
      "metadata": {
        "id": "52sxuajUiF4P"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 50\n",
        "batch_size = 64\n",
        "state_size = 64\n",
        "num_layers = 2\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "HRnMMUm9iPuw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n"
      ],
      "metadata": {
        "id": "5me5_hIciTk4"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(units=state_size, return_sequences=True, input_shape=(max_seq_length, 1)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=state_size, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=state_size))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=num_classes, activation='softmax'))"
      ],
      "metadata": {
        "id": "KmtUgzWyiZ83"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "-PSC_hfoidoA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FF6eeyIuihEn",
        "outputId": "c1b17f9e-718e-4b4e-969d-c4857717ca8c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 682 samples\n",
            "Epoch 1/50\n",
            "682/682 [==============================] - 1s 2ms/sample - loss: 1.0987 - accuracy: 0.3680\n",
            "Epoch 2/50\n",
            "682/682 [==============================] - 0s 263us/sample - loss: 1.0827 - accuracy: 0.3607\n",
            "Epoch 3/50\n",
            "682/682 [==============================] - 0s 277us/sample - loss: 1.0377 - accuracy: 0.4326\n",
            "Epoch 4/50\n",
            "682/682 [==============================] - 0s 281us/sample - loss: 0.9710 - accuracy: 0.4897\n",
            "Epoch 5/50\n",
            "682/682 [==============================] - 0s 253us/sample - loss: 0.9461 - accuracy: 0.5088\n",
            "Epoch 6/50\n",
            "682/682 [==============================] - 0s 263us/sample - loss: 0.9172 - accuracy: 0.5616\n",
            "Epoch 7/50\n",
            "682/682 [==============================] - 0s 255us/sample - loss: 0.9187 - accuracy: 0.5132\n",
            "Epoch 8/50\n",
            "682/682 [==============================] - 0s 260us/sample - loss: 0.9169 - accuracy: 0.5411\n",
            "Epoch 9/50\n",
            "682/682 [==============================] - 0s 281us/sample - loss: 0.9012 - accuracy: 0.5103\n",
            "Epoch 10/50\n",
            "682/682 [==============================] - 0s 273us/sample - loss: 0.8823 - accuracy: 0.5249\n",
            "Epoch 11/50\n",
            "682/682 [==============================] - 0s 258us/sample - loss: 0.8696 - accuracy: 0.5557\n",
            "Epoch 12/50\n",
            "682/682 [==============================] - 0s 440us/sample - loss: 0.8677 - accuracy: 0.5279\n",
            "Epoch 13/50\n",
            "682/682 [==============================] - 0s 486us/sample - loss: 0.8628 - accuracy: 0.5249\n",
            "Epoch 14/50\n",
            "682/682 [==============================] - 0s 443us/sample - loss: 0.8645 - accuracy: 0.5396\n",
            "Epoch 15/50\n",
            "682/682 [==============================] - 0s 447us/sample - loss: 0.8558 - accuracy: 0.5381\n",
            "Epoch 16/50\n",
            "682/682 [==============================] - 0s 463us/sample - loss: 0.8391 - accuracy: 0.5616\n",
            "Epoch 17/50\n",
            "682/682 [==============================] - 0s 448us/sample - loss: 0.8247 - accuracy: 0.5762\n",
            "Epoch 18/50\n",
            "682/682 [==============================] - 0s 444us/sample - loss: 0.8410 - accuracy: 0.5323\n",
            "Epoch 19/50\n",
            "682/682 [==============================] - 0s 429us/sample - loss: 0.8362 - accuracy: 0.5645\n",
            "Epoch 20/50\n",
            "682/682 [==============================] - 0s 475us/sample - loss: 0.8293 - accuracy: 0.5557\n",
            "Epoch 21/50\n",
            "682/682 [==============================] - 0s 343us/sample - loss: 0.8256 - accuracy: 0.5381\n",
            "Epoch 22/50\n",
            "682/682 [==============================] - 0s 256us/sample - loss: 0.8207 - accuracy: 0.5762\n",
            "Epoch 23/50\n",
            "682/682 [==============================] - 0s 257us/sample - loss: 0.8269 - accuracy: 0.5689\n",
            "Epoch 24/50\n",
            "682/682 [==============================] - 0s 259us/sample - loss: 0.8245 - accuracy: 0.5733\n",
            "Epoch 25/50\n",
            "682/682 [==============================] - 0s 286us/sample - loss: 0.8103 - accuracy: 0.5660\n",
            "Epoch 26/50\n",
            "682/682 [==============================] - 0s 260us/sample - loss: 0.7995 - accuracy: 0.5909\n",
            "Epoch 27/50\n",
            "682/682 [==============================] - 0s 260us/sample - loss: 0.8061 - accuracy: 0.5616\n",
            "Epoch 28/50\n",
            "682/682 [==============================] - 0s 269us/sample - loss: 0.7963 - accuracy: 0.6188\n",
            "Epoch 29/50\n",
            "682/682 [==============================] - 0s 264us/sample - loss: 0.7950 - accuracy: 0.5924\n",
            "Epoch 30/50\n",
            "682/682 [==============================] - 0s 290us/sample - loss: 0.7944 - accuracy: 0.5968\n",
            "Epoch 31/50\n",
            "682/682 [==============================] - 0s 259us/sample - loss: 0.7891 - accuracy: 0.6158\n",
            "Epoch 32/50\n",
            "682/682 [==============================] - 0s 271us/sample - loss: 0.7917 - accuracy: 0.6246\n",
            "Epoch 33/50\n",
            "682/682 [==============================] - 0s 298us/sample - loss: 0.7805 - accuracy: 0.6378\n",
            "Epoch 34/50\n",
            "682/682 [==============================] - 0s 266us/sample - loss: 0.7887 - accuracy: 0.6114\n",
            "Epoch 35/50\n",
            "682/682 [==============================] - 0s 268us/sample - loss: 0.7910 - accuracy: 0.6202\n",
            "Epoch 36/50\n",
            "682/682 [==============================] - 0s 277us/sample - loss: 0.8023 - accuracy: 0.6144\n",
            "Epoch 37/50\n",
            "682/682 [==============================] - 0s 280us/sample - loss: 0.8062 - accuracy: 0.5792\n",
            "Epoch 38/50\n",
            "682/682 [==============================] - 0s 256us/sample - loss: 0.7911 - accuracy: 0.6100\n",
            "Epoch 39/50\n",
            "682/682 [==============================] - 0s 256us/sample - loss: 0.7880 - accuracy: 0.6305\n",
            "Epoch 40/50\n",
            "682/682 [==============================] - 0s 284us/sample - loss: 0.7567 - accuracy: 0.6496\n",
            "Epoch 41/50\n",
            "682/682 [==============================] - 0s 291us/sample - loss: 0.7757 - accuracy: 0.6290\n",
            "Epoch 42/50\n",
            "682/682 [==============================] - 0s 267us/sample - loss: 0.7945 - accuracy: 0.5894\n",
            "Epoch 43/50\n",
            "682/682 [==============================] - 0s 275us/sample - loss: 0.7865 - accuracy: 0.6144\n",
            "Epoch 44/50\n",
            "682/682 [==============================] - 0s 268us/sample - loss: 0.7767 - accuracy: 0.6232\n",
            "Epoch 45/50\n",
            "682/682 [==============================] - 0s 264us/sample - loss: 0.7680 - accuracy: 0.6114\n",
            "Epoch 46/50\n",
            "682/682 [==============================] - 0s 288us/sample - loss: 0.7641 - accuracy: 0.6173\n",
            "Epoch 47/50\n",
            "682/682 [==============================] - 0s 269us/sample - loss: 0.7601 - accuracy: 0.6334\n",
            "Epoch 48/50\n",
            "682/682 [==============================] - 0s 283us/sample - loss: 0.7620 - accuracy: 0.6481\n",
            "Epoch 49/50\n",
            "682/682 [==============================] - 0s 281us/sample - loss: 0.7525 - accuracy: 0.6290\n",
            "Epoch 50/50\n",
            "682/682 [==============================] - 0s 279us/sample - loss: 0.7550 - accuracy: 0.6598\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1661bc2fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLekxT5xinwf",
        "outputId": "5b630eaa-26eb-459e-8a55-436698abf8c7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2333: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.64327484\n"
          ]
        }
      ]
    }
  ]
}